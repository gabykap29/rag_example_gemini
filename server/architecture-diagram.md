# Arquitectura del Sistema RAG - Gemini/Ollama

## Diagrama de Arquitectura General

```mermaid
graph TB
    %% Cliente
    Client[ğŸŒ Cliente Web/API]
    
    %% API Layer
    subgraph API["ğŸš€ API Layer (FastAPI)"]
        GenerateEndpoint["/generate<br/>ğŸ“ Actividades Educativas"]
        StudentEndpoint["/generate/student<br/>ğŸ“ Asistente Educativo"]
        DocumentsEndpoint["/documents/upload<br/>ğŸ“„ Subida de Documentos"]
    end
    
    %% Services Layer
    subgraph Services["âš™ï¸ Services Layer"]
        GenerateService[generate_response<br/>ğŸ”„ LÃ³gica de GeneraciÃ³n]
        AssistantService[generate_response_assistant<br/>ğŸ¤– Asistente Virtual]
        DocumentsService[upload_document<br/>ğŸ“‚ Procesamiento de Docs]
    end
    
    %% Core Layer
    subgraph Core["ğŸ”§ Core Layer"]
        ModelsCore[models.py<br/>ğŸ§  LLM Integration]
        DocumentsCore[documents.py<br/>ğŸ“š GestiÃ³n de Documentos]
        VectorCore[vectorstore.py<br/>ğŸ” Vector Database]
    end
    
    %% AI Models
    subgraph AIModels["ğŸ¤– AI Models"]
        Gemini[Google Gemini 2.0<br/>ğŸŒŸ Modelo Principal]
        Ollama[Ollama<br/>ğŸ¦™ Modelo Local]
        OllamaStudent[medicina_usuario<br/>ğŸ‘¨â€ğŸ“ Modelo Estudiante]
    end
    
    %% Templates & Config
    subgraph Config["âš™ï¸ Configuration"]
        CustomTemplate[custom_template<br/>ğŸ“‹ Plantilla Educativa]
        UserTemplate[user_template<br/>ğŸ¯ Plantilla Asistente]
        ConfigFile[config.py<br/>ğŸ”§ ConfiguraciÃ³n]
        EnvFile[.env<br/>ğŸ” Variables de Entorno]
    end
    
    %% Data Storage
    subgraph Storage["ğŸ’¾ Data Storage"]
        ChromaDB[(ChromaDB<br/>ğŸ” Vector Database)]
        Documents[(Documents<br/>ğŸ“ PDF/DOCX Files)]
        Logs[(Logs<br/>ğŸ“Š Sistema de Logs)]
    end
    
    %% Utils
    subgraph Utils["ğŸ› ï¸ Utilities"]
        Filters[filters.py<br/>ğŸ§¹ Filtros de Texto]
        Logging[logging.py<br/>ğŸ“ Sistema de Logs]
        Probability[probability.py<br/>ğŸ“ˆ CÃ¡lculo de Similitud]
    end
    
    %% External Services
    subgraph External["ğŸŒ External Services"]
        GoogleAPI[Google AI API<br/>ğŸ”— Gemini Access]
        OllamaAPI[Ollama API<br/>ğŸ“¡ Local LLM Server]
    end
    
    %% Conexiones principales
    Client --> API
    
    %% API to Services
    GenerateEndpoint --> GenerateService
    StudentEndpoint --> AssistantService
    DocumentsEndpoint --> DocumentsService
    
    %% Services to Core
    GenerateService --> ModelsCore
    GenerateService --> DocumentsCore
    AssistantService --> ModelsCore
    DocumentsService --> DocumentsCore
    DocumentsService --> VectorCore
    
    %% Core to Storage and External
    ModelsCore --> AIModels
    DocumentsCore --> ChromaDB
    DocumentsCore --> Documents
    VectorCore --> ChromaDB
    
    %% AI Models to External APIs
    Gemini --> GoogleAPI
    Ollama --> OllamaAPI
    OllamaStudent --> OllamaAPI
    
    %% Configuration
    ModelsCore --> Config
    Core --> Utils
    
    %% Logging
    API --> Logs
    Services --> Logs
    Core --> Logs
    
    %% Styling
    classDef apiStyle fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef serviceStyle fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef coreStyle fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef aiStyle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef storageStyle fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef configStyle fill:#f1f8e9,stroke:#33691e,stroke-width:2px
    classDef utilStyle fill:#e0f2f1,stroke:#004d40,stroke-width:2px
    classDef extStyle fill:#fafafa,stroke:#424242,stroke-width:2px
    
    class API apiStyle
    class Services serviceStyle
    class Core coreStyle
    class AIModels aiStyle
    class Storage storageStyle
    class Config configStyle
    class Utils utilStyle
    class External extStyle
```

## Flujo de Datos Detallado

### 1. GeneraciÃ³n de Actividades Educativas

```mermaid
sequenceDiagram
    participant C as Cliente
    participant GE as /generate Endpoint
    participant GS as GenerateService
    participant DC as DocumentsCore
    participant MC as ModelsCore
    participant VS as VectorStore
    participant AI as LLM (Gemini/Ollama)
    
    C->>GE: POST /generate (GenerateRequest)
    GE->>GS: generate_response()
    
    %% RecuperaciÃ³n de documentos
    GS->>DC: retrieve_docs(unidad, materia)
    DC->>VS: similarity_search()
    VS-->>DC: documentos relevantes
    DC-->>GS: context
    
    %% GeneraciÃ³n con IA
    loop MÃ¡ximo 3 intentos
        GS->>MC: generate_response_stream()
        MC->>AI: stream request + context
        AI-->>MC: chunks de respuesta
        MC-->>GS: respuesta completa
        
        %% VerificaciÃ³n de duplicados
        GS->>DC: retrieve_questions()
        DC->>VS: similarity_search(pregunta)
        VS-->>DC: preguntas similares + score
        DC-->>GS: similarity score
        
        alt score < 70% (Ãºnica)
            GS->>DC: index_questions()
            DC->>VS: add_documents()
            GS-->>GE: respuesta final
        else score >= 70% (duplicada)
            Note over GS: Agregar a lista de preguntas previas
        end
    end
    
    GE-->>C: GenerateResponse
```

### 2. Asistente Virtual para Estudiantes

```mermaid
sequenceDiagram
    participant C as Cliente
    participant SE as /student Endpoint
    participant AS as AssistantService
    participant MC as ModelsCore
    participant AI as LLM (Modelo Estudiante)
    
    C->>SE: POST /student (RequestStudent)
    SE->>AS: generate_response_assistant()
    AS->>MC: generate_response_student()
    
    alt Modelo = "OLLAMA"
        MC->>AI: chat(model_student, messages)
        AI-->>MC: chunks de respuesta
    else Modelo = "GEMINI"
        MC->>AI: chain.stream(contexto, pregunta)
        AI-->>MC: chunks de respuesta
    end
    
    MC-->>AS: chunks
    AS->>AS: join chunks to full_response
    AS-->>SE: respuesta completa
    SE-->>C: respuesta del asistente
```

### 3. Subida y Procesamiento de Documentos

```mermaid
sequenceDiagram
    participant C as Cliente
    participant DE as /documents/upload
    participant DS as DocumentsService
    participant DC as DocumentsCore
    participant VS as VectorStore
    participant FS as FileSystem
    
    C->>DE: POST /upload (file, subject)
    DE->>DS: upload_document()
    DS->>FS: save file to disk
    
    DS->>DC: load_document()
    alt PDF
        DC->>DC: PDFPlumberLoader.load()
    else DOCX
        DC->>DC: Docx2txtLoader.load()
    end
    DC-->>DS: documents
    
    DS->>DC: index_docs()
    DC->>DC: split_documents()
    DC->>VS: add_documents()
    DC->>VS: persist()
    
    DS-->>DE: UploadResponse
    DE-->>C: resultado de la subida
```

## Componentes Clave

### Templates de Prompts

```mermaid
graph LR
    subgraph Templates["ğŸ“‹ Sistema de Templates"]
        CT[custom_template<br/>ğŸ¯ GeneraciÃ³n de Actividades]
        UT[user_template<br/>ğŸ¤– Asistente Virtual]
        
        CT --> |Usado por| Generate[generate_response_stream]
        UT --> |Usado por| Student[generate_response_student]
    end
    
    subgraph Features["âœ¨ CaracterÃ­sticas"]
        AT[Tono Educativo<br/>ğŸ“š]
        AR[Anti-RepeticiÃ³n<br/>ğŸ”„]
        JS[Formato JSON<br/>ğŸ“]
        EM[EmpÃ¡tico y Paciente<br/>ğŸ’™]
    end
    
    CT --> AT
    CT --> AR  
    CT --> JS
    UT --> EM
    UT --> JS
```

### Sistema de Vector Database

```mermaid
graph TB
    subgraph VectorDB["ğŸ” ChromaDB Vector Storage"]
        MC[Materia Collections<br/>ğŸ“š Documentos por materia]
        QC[Question Collections<br/>â“ Preguntas generadas]
        
        subgraph Embeddings["ğŸ”¤ Embeddings"]
            NE[nomic-embed-text<br/>ğŸ¦™ Ollama Embeddings]
        end
    end
    
    subgraph Operations["âš™ï¸ Operaciones"]
        SS[Similarity Search<br/>ğŸ” BÃºsqueda semÃ¡ntica]
        AD[Add Documents<br/>â• IndexaciÃ³n]
        RD[Retrieve Docs<br/>ğŸ“– RecuperaciÃ³n]
    end
    
    MC --> SS
    QC --> SS
    NE --> MC
    NE --> QC
    SS --> RD
    AD --> MC
    AD --> QC
```

### ConfiguraciÃ³n y Variables de Entorno

```mermaid
graph LR
    subgraph EnvConfig["ğŸ”§ ConfiguraciÃ³n"]
        ENV[.env<br/>ğŸ” Variables de Entorno]
        CONFIG[config.py<br/>âš™ï¸ ConfiguraciÃ³n Central]
    end
    
    subgraph Variables["ğŸ“Š Variables Principales"]
        MODEL[MODEL<br/>ğŸ¤– GEMINI/OLLAMA]
        API_KEY[API_KEY<br/>ğŸ”‘ Google AI]
        OLLAMA_URL[OLLAMA_URL<br/>ğŸŒ Servidor Local]
        MODEL_STUDENT[MODEL_USER_OLLAMA<br/>ğŸ‘¨â€ğŸ“ Modelo Estudiante]
    end
    
    ENV --> CONFIG
    CONFIG --> MODEL
    CONFIG --> API_KEY
    CONFIG --> OLLAMA_URL
    CONFIG --> MODEL_STUDENT
```

## Patrones ArquitectÃ³nicos Implementados

1. **ğŸ—ï¸ Layered Architecture**: API â†’ Services â†’ Core â†’ Storage
2. **ğŸ”„ Repository Pattern**: AbstracciÃ³n de acceso a datos
3. **ğŸ¯ Strategy Pattern**: Intercambio entre Gemini y Ollama
4. **ğŸ“‹ Template Method**: ReutilizaciÃ³n de lÃ³gica de generaciÃ³n
5. **ğŸ” RAG (Retrieval-Augmented Generation)**: Enriquecimiento contextual
6. **ğŸ“Š Logging Pattern**: Trazabilidad completa de operaciones
7. **âš¡ Streaming Pattern**: Respuestas en tiempo real

## TecnologÃ­as Utilizadas

- **ğŸš€ FastAPI**: Framework web asÃ­ncrono
- **ğŸ¦œ LangChain**: OrquestaciÃ³n de LLMs
- **ğŸ” ChromaDB**: Base de datos vectorial
- **ğŸŒŸ Google Gemini 2.0**: Modelo de IA principal
- **ğŸ¦™ Ollama**: Servidor de modelos locales
- **ğŸ“„ PDFPlumber/Docx2txt**: Procesamiento de documentos
- **ğŸ”¤ Nomic Embed**: Embeddings de texto
- **ğŸ“ Pydantic**: ValidaciÃ³n de datos
- **ğŸ“Š Python Logging**: Sistema de logs
